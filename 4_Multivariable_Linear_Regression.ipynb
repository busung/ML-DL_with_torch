{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Multivariable Linear Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPs+KVqiqcvl7bvyBtmSXD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/busung/ML-DL_with_torch/blob/main/4_Multivariable_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "o-Ck6ZBuGvc8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "smGRJefwGG0v"
      },
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[73,80,75],\n",
        "                             [93,88,93],\n",
        "                             [89,91,90],\n",
        "                             [96,98,100],\n",
        "                             [73,66,70]])\n",
        "\n",
        "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#다변량 회귀이기에 W값이 Vector로 주어짐\n",
        "W = torch.zeros((3,1),requires_grad=True)\n",
        "b = torch.zeros(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "jzW3V9XJGuyl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD([W,b],lr=1e-5)"
      ],
      "metadata": {
        "id": "EMPRL0dwHV91"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "\n",
        "for epoch in range(0,nb_epochs+1):\n",
        "\n",
        "  #다변량 회귀이기에 행렬의 곱으로 y값을 추정함\n",
        "  hypothesis = x_train.matmul(W)+b\n",
        "\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(\"Epoch={} hypothesis={}, cost={:4f}\".format(epoch,hypothesis.squeeze().detach(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMg2S5oIHcqX",
        "outputId": "a8142b6b-b201-4c60-fb66-7b0760af7444"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0 hypothesis=tensor([0., 0., 0., 0., 0.]), cost=29661.800781\n",
            "Epoch=1 hypothesis=tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]), cost=9298.520508\n",
            "Epoch=2 hypothesis=tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]), cost=2915.712402\n",
            "Epoch=3 hypothesis=tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]), cost=915.040527\n",
            "Epoch=4 hypothesis=tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]), cost=287.936096\n",
            "Epoch=5 hypothesis=tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]), cost=91.371063\n",
            "Epoch=6 hypothesis=tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]), cost=29.758249\n",
            "Epoch=7 hypothesis=tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]), cost=10.445267\n",
            "Epoch=8 hypothesis=tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]), cost=4.391237\n",
            "Epoch=9 hypothesis=tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]), cost=2.493121\n",
            "Epoch=10 hypothesis=tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]), cost=1.897688\n",
            "Epoch=11 hypothesis=tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]), cost=1.710552\n",
            "Epoch=12 hypothesis=tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]), cost=1.651416\n",
            "Epoch=13 hypothesis=tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]), cost=1.632369\n",
            "Epoch=14 hypothesis=tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]), cost=1.625924\n",
            "Epoch=15 hypothesis=tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]), cost=1.623420\n",
            "Epoch=16 hypothesis=tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]), cost=1.622152\n",
            "Epoch=17 hypothesis=tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]), cost=1.621262\n",
            "Epoch=18 hypothesis=tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]), cost=1.620501\n",
            "Epoch=19 hypothesis=tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]), cost=1.619757\n",
            "Epoch=20 hypothesis=tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]), cost=1.619046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Torch 내장 함수로 학습\n",
        "* nn.Module을 통하여 위의 행렬 연산을 자동으로 해줌"
      ],
      "metadata": {
        "id": "3AC2Yeq9OATc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "#torch에서 지원해 주는 Function을 활용하면 훨씬 편하게 교체하거나 학습을 할 수 있음\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    #위의 행렬연산을 이렇게 간단하게 표현 할 수 있음\n",
        "    self.linear = nn.Linear(3,1)#(입력,출력)\n",
        "\n",
        "  def forward(self,x):#hypothesis 계산을 자동적으로 실행시켜 줌\n",
        "    return self.linear(x)"
      ],
      "metadata": {
        "id": "YB1TAF8jODjp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "\n",
        "model = MultiRegressionModel()\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)\n",
        "\n",
        "for epoch in range(0,nb_epochs+1):\n",
        "\n",
        "  #다변량 회귀이기에 행렬의 곱으로 y값을 추정함\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  cost = F.mse_loss(hypothesis,y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(\"Epoch={} hypothesis={}, cost={:4f}\".format(epoch,hypothesis.squeeze().detach(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XvGKgf1P4sp",
        "outputId": "05b7daa6-b685-46fa-e1dc-f03f05440229"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch=0 hypothesis=tensor([-53.0262, -60.6310, -61.2418, -67.5033, -44.8735]), cost=52984.726562\n",
            "Epoch=1 hypothesis=tensor([36.8683, 47.4154, 45.2182, 48.4290, 37.5387]), cost=16608.058594\n",
            "Epoch=2 hypothesis=tensor([ 87.1970, 107.9066, 104.8213, 113.3353,  83.6782]), cost=5205.907715\n",
            "Epoch=3 hypothesis=tensor([115.3743, 141.7733, 138.1909, 149.6739, 109.5100]), cost=1631.939087\n",
            "Epoch=4 hypothesis=tensor([131.1497, 160.7341, 156.8733, 170.0186, 123.9722]), cost=511.689758\n",
            "Epoch=5 hypothesis=tensor([139.9819, 171.3494, 167.3329, 181.4089, 132.0690]), cost=160.550629\n",
            "Epoch=6 hypothesis=tensor([144.9267, 177.2926, 173.1889, 187.7858, 136.6021]), cost=50.487354\n",
            "Epoch=7 hypothesis=tensor([147.6951, 180.6199, 176.4675, 191.3561, 139.1399]), cost=15.988371\n",
            "Epoch=8 hypothesis=tensor([149.2451, 182.4827, 178.3030, 193.3550, 140.5608]), cost=5.174634\n",
            "Epoch=9 hypothesis=tensor([150.1130, 183.5256, 179.3307, 194.4741, 141.3562]), cost=1.785146\n",
            "Epoch=10 hypothesis=tensor([150.5989, 184.1095, 179.9061, 195.1006, 141.8015]), cost=0.722663\n",
            "Epoch=11 hypothesis=tensor([150.8710, 184.4363, 180.2282, 195.4514, 142.0508]), cost=0.389607\n",
            "Epoch=12 hypothesis=tensor([151.0233, 184.6193, 180.4086, 195.6478, 142.1903]), cost=0.285191\n",
            "Epoch=13 hypothesis=tensor([151.1087, 184.7217, 180.5096, 195.7578, 142.2684]), cost=0.252449\n",
            "Epoch=14 hypothesis=tensor([151.1565, 184.7790, 180.5661, 195.8194, 142.3120]), cost=0.242158\n",
            "Epoch=15 hypothesis=tensor([151.1833, 184.8110, 180.5978, 195.8539, 142.3364]), cost=0.238905\n",
            "Epoch=16 hypothesis=tensor([151.1984, 184.8289, 180.6155, 195.8732, 142.3501]), cost=0.237874\n",
            "Epoch=17 hypothesis=tensor([151.2068, 184.8390, 180.6255, 195.8840, 142.3577]), cost=0.237528\n",
            "Epoch=18 hypothesis=tensor([151.2116, 184.8445, 180.6311, 195.8901, 142.3619]), cost=0.237391\n",
            "Epoch=19 hypothesis=tensor([151.2143, 184.8476, 180.6342, 195.8935, 142.3642]), cost=0.237332\n",
            "Epoch=20 hypothesis=tensor([151.2159, 184.8493, 180.6360, 195.8954, 142.3654]), cost=0.237289\n"
          ]
        }
      ]
    }
  ]
}